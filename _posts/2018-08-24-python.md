##### 函数
默认参数的函数
可以简化函数的调用，并增加函数的扩展性

```
def power(x, n=2)
	s = 1
	while n > 0
		n = n - 1
		s = s * x
	return s

power(5)
power(5,3)
```

默认参数注意点，默认参数必须指向不变对象

```
def add_end(L=[])
	L.append('END')
	return L

add_end()
['END']

add_end()
['END','END']

add_end()
['END','END','END']

```

原因是Python函数在定义的时候，默认参数L的值就被计算出来了，即[],因为默认参数L也是一个变量，它指向对象[]，每次调用该函数，如果改变了L的内容，则下次调用时，默认参数的内容就变了，不再是函数定义时的[]了。

```
def add_end(L=None)
	if L is Node:
		L = []
	L.append('END')
	return L
```

#### 可变参数
传入的参数是不固定的

```
def calc(numbers):
	sum = 0
	for n in mubers:
		sum = sum + n * n
	return sum
calc([1,2,3])
```

利用可变参数，调用函数的方式可以简化成

```
calc(1,2,3)
calc(1,3,5,7)
```

可变函数的格式
```
def calc(*numbers):
	sum = 0
	for n in numbers:
		sum = sum + n * n
	return sum
```

定义可变参数和定义一个List或tuple参数相比，仅仅在参数前面加了一个*号。在函数内部，参数numbers接收到的是一个tuple,

list或tuple传入一个可变参数

```
nums = [1,2,3]
calc(*nums)
```
Python允许你在list或tuple前面加一个*号，把List货tuple的元素变成可变参数传进去。

##### 关键字参数
可变参数允许你传入0个或任意个参数，这些可变参数在函数调用时自动组装成一个tuple。而关键字参数允许你传入0个或任意个含参数名的参数，这些关键字参数在内部自动组装成dict

```
def person(name, age, **kw)
 	print('name':name,'age':age,'other',kw)
```

##### 命名关键字参数
用于限制关键字参数的名字，例如只接收city和job作为关键字参数

```
def person(name,age,*,city,job):
	print(name,age,city,job)
	
person('Jack',24,city='Beijin',job='Enginner')
```

如果函数中已经有了一个可变参数，后面跟着的命名关键字参数就不需要一个特殊分隔符*了：

```
def person(name,age,*arg,city,job)
	print(name,age,args,city,job)

person('xx','23','sss','xxx')
由于调用时缺少参数名city和job，Python解释器把这4个参数均视为位置参数，但person()函数仅接收两个位置参数。故而会报错。

```

带默认值的命名关键字参数
```
def person(name,age,*arg,city='beijin',job)
 	print(name,age,arg,city,job)
```

对于任意参数组合，通可以通过类似func(*args,**kw)的形式调用它。


#### 递归函数

我看到最容量理解解决汉诺塔的递归函数

```
def move(n,a,b,c)
	if n == 1:
		print(a,'-->',c)
	else:
		move(n-1,a,c,b)
		move(1,a,b,c)
		move(n-1,b,a,c)
```

#### 高级特性
##### 切片（Slice）
L[0:3]表示，从索引0开始取，直到索引3为止，但不包括索引3.
索引开始为0等价于L[:3]
倒数切片
L[-2:] 从倒数第二个开始取
tuple也可以用切片操作

##### 迭代
python 中迭代是通过for ... in 来完成
只要是可以迭代的对象都可以用for ... in

```
d = {'a':1,'b':2,'c':3}
for key in d:
	print(key)

```
dict迭代的是Key,如果要迭代value可以用for value in d.value,如果要迭代key和value，可以用for k, v in d.items()

判断一个对象是否可以迭代，方法是通过collections模块的iterable类型判断

对list实现类似java那样的下标循环，python内置的enumerate函数可以吧list变成索引-元素对
for i,value in enumerate(['a','b','c'])
	print(i,value)
	
##### 装饰器

函数对象有一个__name__属性，可以拿到函数的名字

在代码运行期间动态增加功能的方式，称之为装饰器("Decorator")

本质上，decorator就是一个返回函数的高价函数，所以，我们要定义一个能打印日志的decorator

```
def log(func):
	def wrapper(*args,**kw):
		print('call %():' % func.__name__)
		return func(*args,**kw)
	return wrapper

@log
def now():
	print('2015-3-25')

```
把@log放到now()函数定义处，相当于执行了语句
now = log(now)

由于log()是一个decorator,返回一个函数，原来的now()函数仍然存在，只是现在同名的now变量指向了新的函数，于是调用now()函数将执行新的函数，即在wrapper中返回的wrapper函数()

如果decorator本身需要传入参数，那就需要编写一个返回decorator的高价函数。

```
def log(text)
	def decorator(func):
		def wrapper(*args,**kw)
			print('%s %s():' % (text,func.__name__))
			return func(*arg,**kw)
		return wrapper
	return decorator

@log('execute')
def now():
	print('2015-3-25')
	
```
三层嵌套的效果是
now = log('execute')(now)

可以看出返回值最终是wrapper函数。所以__name__已经从原来的'now'变成了'wrapper',可以通过functools.wraps模块解决这个问题

```
import functools

def log(func):
	@functools.wraps(func)
	def wrapper(*args, **kw):
		print('call %():' % func.__name__)
		return func(*arg,**kw)
	return wrapper
	
	import functools

def log(text):
    def decorator(func):
        @functools.wraps(func)
        def wrapper(*args, **kw):
            print('%s %s():' % (text, func.__name__))
            return func(*args, **kw)
        return wrapper
    return decorator
```

python直接从语法层次支持decorator,OOP的装饰模式需要通过继承和组合来实现


#### 偏函数
通过设定默认值，可以降低函数调用的难度。而偏函数可以做到这点，通过设置默认值指定成一个新的函数

```
import functools
int2 = functools.partial(int, base = 2)
int2('100000')

max2 = functools.partial(max, 10)
max2(5,6,7)
相当于
max2(10,5,6,7)
```

自定义偏函数实现

```
def my_partial(func, *args, **kw):
	@functools.wraps(func)
	def wrapper(*arg):
		return func(*args+arg, **kw)
	return wrapper
```

#### 第三方模块
通过Anaconada3管理python,安装brew cask install anaconad

设置环境变量
export PATH=/usr/local/anaconda3/bin:"$PATH"

Anaconda3也会给你默认安装一个python3.6的稳定版本，设置python3.7需要进行如下操作

```
conda create -n py37 python=3.7
source active py37
python -V
```

**注意前面conda自带的一些第三方依赖没有为新安装的3.7设置依赖，只需要安装一下即可**
```
conda install numpy
```

#### 面向对象编程
访问限制
如果要让内部属性不被外部访问，可以把属性名称前加上两个下划线__，表示为私有

class Student(object):

	def __init__(self,name,score):
		self.__name = name
		self.__score = scor
		
创建一个class的实例后，我们可以给实例绑定任何属性和方法，这是动态语言的灵活性
通过__slots__变量，可以限制改class实例能添加的属性

```
clsss Student(object):
	__slots__ = ('name','age')
```

\__slots__关键字只对当前类实例起作用，对继承的子类是不起作用的

#### 定制类

```
__str__



class Student(object):
	def __str__(self):
		return 'xxxxxx'

__iter__
__next__	
class Fib(object):
	"""docstring for Fib"""
	def __init__(self):
		self.a, self.b = 0,1

	def __iter__(self):
		return self

	def __next__(self):
		self.a,self.b = self.b,self.a + self.b
		if self.a > 100000:
			raise StopIteration()
		return self.a
		
__getitem__
可以实现下标访问
		
		
```

当调用不存在的属性的时候，会调用下面方法
```
def _getattr__(self, attr):
```

设置属性时候调用
```
def __setattr__(self, attr):
	
```

下面代码通过重载__getattr__和__setattr__，可以吧self[key]和self.key两种方式关联起来

```
class Model(dict):
	def __getattr__(self,key):
		try return self[key]
	except KeyError:
		raise AttributeError('xxxxx')
		
	def _setattr_(self, key, value):
		self[key] = value
```


#### 枚举类
用法示例
```
from enum import Enum, unique

@unique
class Weekday(Enum):
	Sun = 0
	Mon = 1
	Tue = 2
	Wed = 3
	Thu = 4
	Fri = 5
	Sat = 6
```
@unique装饰器可以帮助我们检查没有重复值。

#### 使用元类
##### type()
动态语言和静态语言最大的不同，就是函数和类的定义，不是编译时定义的，而是运行时动态创建的。
type()函数可以查看一个类型或变量的类型
class的定义是运行时期动态创建的，创建class的方法就是使用type()函数
type()函数既可以返回一个对象的类型，又可以创建出新的类型

type函数创建类
type('类名',(父类,),dict)

要创建一个class对象，type()函数依次传入3个参数:

1. class的名称
2. 继承的父类集合
3. class的方法名称与函数绑定，这里我们把函数fn绑定到方法名hello上

metaclass
除了使用type()动态创建类外，要控制类的创建行为，还可以使用mataclass.
它的解释是：
当我们定义了类以后，就可以根据这个类创建出实例，所以：先定义类，然后创建实例。  
但是如果我们想创建出类呢？那就必须根据metaclass创建出来，所以：先定义metaclass,然后创建类。  
链接起来就是：先定义metaclass,就可以创建类，最后创建实例

```
class ListMetaclass(type):
	def __new__(cls,name,base,attrs):
		attrs['add'] = lambda self, value:self.append(value)
		return type.__new__(cls,name,bases,attrs)
class MyList(list,metaclass=ListMetaclass):
	pass
```
\__new()\__方法接收的参数依次是:

* 1.当前准备创建的类对象；
* 2.类的名字；
* 3.类继承的父类集合；
* 4.类的方法集合

动态修改有什么意义，在MyList定义中写上add()方法不是很简单吗？正常情况下，确实应该直接写，通过metaclass修改纯属变态。  
但是，总会遇到需要metaclass修改类定义的，ORM是一个典型的例子
ORM-Object Relational Mapping,即对象-关系映射，就是把关系数据库的一行映射为一个对象，也就是一个雷对应一个表。  
编写一个ORM框架，所有的类都只能动态定义，因为只有使用者才能根据表的结果定义出对应的类来。










#### 文件读写
读写文件是最常见的IO操作。Python内置类读写文件的函数，用法和C是兼容的
在磁盘上读写文件的功能都是由操作系统提供的，现在操作系统不允许普通的程序直接操作磁盘，读写文件就是请求操作系统打开一个文件对象(通常称为文件描述)，然后，通过操作系统提供的接口从这个文件描述中读取数据，或写数据

##### 读文件

```
f = open('Users/jsonsnow/text.txt','r')
```

如果文件读取成功，接下来，调用read()方法可以一次读取文件的全部内容，Python把内容读取到内存，用一个str对象表示  
最后一步是调用close()方法关闭文件。文件使用完毕后必须关闭，因为文件对象会占用操作系统的资源，并且操作系统同一时间打开的文件数量是有限的。

```
f.close()
```

由于文件读写都有可能产生IOError,一旦出错，后面的f.close()就不会调用

```
try:
	f = open('path/to/file','r')
	print(f.read())
finally:
	if f:
		f.close()
		
```

python引入了with语句来自动帮我们调用close()方法：

```
with open('/path/to/file','r') as f:
	print(f.read())
```
read()会一次性读取文件的全部内容，如果文件有10g，内存就爆了，可以反复调用read(size)方法  
readline()可以每次读取一行内容，调用readlines()一次读取所有内容，并按行返回list。因此更具需求决定怎样调用  
如果文件很小，read()一次性读取最方便；如果不确定文件大小，反复调用read(size)比较保险，如果是配置文件readlines()最方便。

```
for line in f.readlines():
	print(line.strip())
```

#### file-like Object
像open()返回的这种有read()方法的对象，在python中统称为file-like Object.除了file外，还可以是内存的字节流，网络流，自定义流等。file-like Object不要求指定类继承，只需要写个read()方法就行。

StringIO就是在内存中创建的file-like Object,常用作临时缓冲。

#### 二进制文件
前面默认都是读取文本文件，并且是UTF-8编码的文本文件，要读取二进制文件，比如图片、视频等等，用'rb'方式打开。

```
f = open('/Users/michal/test.jpg','rb')
f.read()
```	

#### 字符编码
要读取非UTF-8编码的文本文件，需要给open()函数传入encoding参数，例如，读取GBK编码的文件。

```
f = open('Users/snow/michal/gbk.txt','r',encoing='gbk')
f.read()
```

遇到游戏编码不规范的文件，你可能会遇到UnicodeDecodeError,因为在文本文件中可能夹杂了一些非法编码的字符，遇到这种情况，open()还能接收一个errors参数，表示如果遇到编码错误后如何处理。最简单的方式是直接忽略。

```
f = open('/Users/snow/gbk.txt','r',encoding = 'gbk',error='ignore')
```

#### 写文件
写文件和读文件是一样的，唯一区别是调用open()函数时，传入标识符'w'或者'wb'表示文本文件或写二进制文件:

```
f = open('/Users/snow/test.txt','w')
f.write('Hello ,world!')
f.cloe()
```

你可以反复调用write()来写入文件，但是务必调用f.close()来关闭文件。当我们写文件时，操作系统往往不会立刻写入磁盘，而是放在内存缓存起来，空闲的时候再慢慢写入。只有调用close()方法，操作系统才保证把没写入内存的数据全部写入磁盘。

```
with open('/Users/snow/txt.txt','w') as f:
	f.write('Hello ,world!')
```
上面方式会直接覆盖已存在的文件

要写入特定编码的文本文件，请给open()函数传入encoding参数，将字符串自动转换成指定编码。

```
with open('/Users/snow/txt.txt','a') as f:
	f.write('Hello ,world!')
```

#### StringIO和BytesIO
StringIO在内存中读写str

```
from io import StringIO
f = StringIO()
f.write('hello')
f.write(' ')
f.wirte('world!')
print(f.getvalue())
```

BytesIO实现了在内存中读取bytes，

```
from io import BytesIO
f = BytesIO()
f.write('中文'.encode('utf-8'))
print(f.getvalue())

f = BytesIO(b'\xe4\xb8\xad\xe6\x96\x87')
f.read()

```

#### 序列化
在程序运行的过程中，所有变量都是在内存中 
把变量从内存中变成可存储或传输的过程称之为序列化，在python中叫picklink,在其他语言中称之为serialization,marshalling,flatening等等。  
徐序列化之后，就可以吧序列化后的内容写入磁盘，或者通过网络传输到别的机器上。  
反过来，把变量内容从序列化的对象重新独到内存里称之为反序列化，unpicking.
不过pickle是python才能识别，下面介绍json

##### json
```
import json
d = dict(name='bob',age=20,score=88)
json_str = json.dumps(d)
json.loads(json_str)

json_str = ''
```

##### JSON进价

```
import json
class Student(object):
	def __init__(self, name, age, score):
		self.name = name
		self.age = age
		self.score = score
		
def student2dict(std):
	return {
		'name':std.name,
		'age':std.age,
		'score':std.score
	}

		
```
对于自定义对象，需要提供一个序列化的函数

```
json.dumps(s,default=student2dict)
```

#### 进程和多线程

Unix/Linux系统的fork()系统调用，它非常特殊。普通的函数调用，调用一次返回一次，fork()调用一次返回两次，因为操作系统自动把当前进程复制了一份，然后分别在父进程和子进程内返回。

子进程永远返回0，而父进程返回子进程的ID。

```
import os
print('Process (%s) start...' % os.getpid())
pid = os.fork()
if pid == 0:
	print('I am child process （%s）and my parant is %s' % (os.getpid(),os.getppid()))
else:
	print('I (%s) just created a child process (%s).' % (os.getpid(),pid))
```


##### multiprocessing 兼容所有平台的服务程序

multiprocessing 提供了一个Process类来代表一个进程对象。

```
rom multiprocessing import Process, Pool

def run_proc(name):
	print('Run child process %s .' % os.getpid())

if __name__ == '__main__':
	print('Parent process %s.' %  os.getpid())
	p = Process(target=run_proc, args=('test',))
	print('Child process will start')
	p.start()
	p.join()
	print('Child process end.')

```

start()方法启动，join()方法可以等待子进程结束后再继续往下运行，通常用于进程间的同步。
p.terminate() 结束进程

#### Pool

```
from multiprocessing impor Pool

def long_time_task(name):
	print('Run task %s (%s)...' % (name, os.getpid()))
	start = time.time()
	time.sleep(random.random() * 3)
	end = time.time()
	print('Task %s runs %0.2f seconds.' % (name, (end - start)))

if __name__ == '__main__':
	print('Parent process %s.' % os.getpid())
	p = Pool(4)
	for i in range(5):
		p.apply_async(long_time_task,args=(i,))

	print('Waiting for all subprocesses done...')
	p.close()
	p.join()
	print('All subprocesses done')
```

#### 子进程
很多时候，子进程并不是自身，而是一个外部进程。

#### 进程间的通信
Process之间肯定是需要通信的，操作系统提供了很多机制来实现进程的通信。Python的multiprocessing模块包装了底层的机制，提供了Queue,Pipes等多种方式来交互数据。

```
from multiprocessing import Process, Queue

def write(q):
    print('Process to write: %s' % os.getpid())
    for value in ['A', 'B', 'C']:
        print('Put %s to queue...' % value)
        q.put(value)
        time.sleep(random.random())
        

def read(q):
	print('Process to read：%s' % os.getpid())
	while  True:
		value = q.get(True)
		print('Get %s from queue.' % value)

if __name__ == '__main__':
	q = Queue()
	pw = Process(target = write, args=(q,))
	pr = Process(target = read, args=(q,))
	
	pw.start()
	pr.start()

	pw.join()
	pr.terminate()
```


#### 多线程
Python标准库提供了两个模块，_thread和threading,threading是对_threading的封装。

```

import time, threading

def loop():
	print('thread %s is running ...' % threading.current_thread().name)
	n = 0
	while n < 5:
		n = n + 1
		print('thread %s >>> %s' % (threading.current_thread().name,n))
		time.sleep(1)
	print('thread %s ended.' % threading.current_thread().name)

print('thread %s is running ...' % threading.current_thread().name)
t = threading.Thread(target=loop, name='LoopThread')
t.start()
t.join()
print('thread %s ended.' % threading.current_thread().name)

```

#### Lock
多线程和多进程最大的不同在于，多进程，同一个变量，各自有一份拷贝存在每个进程中，互不影响，而多线程中，所有变量由所有线程共享。

```
balance = 0
lock = threading.Lock()
def change_it(n):
	global balance
	balance = balance + n
	balance = balance - n

def run_thread(n):
	for i in range(100000):
		lock.acquire()
		try:
			change_it(n)
		finally:
			lock.release()
		# change_it(n)

t1 = threading.Thread(target=run_thread, args=(5,))
t2 = threading.Thread(target=run_thread, args=(8,))

t1.start()
t2.start()
t1.join()
t2.join()
print(balance)
```

#### 多核CPU
一个死循环会导致执行该线程的CPU跑满

```
def loop():
	x = 0
	while True:
		x = x ^ 1

for i in range(multiprocessing.cpu_count()):
	t = threading.Thread(target=loop)
	t.start()
```
逻辑上来讲有多少核就会跑到x00%，但查看可值python的程序只跑了102，也就是一核。
因为Python的线程虽然是真正的线程，但解释器执行代码时，有一个GIL锁：Global interpreter Lock,任何Python线程执行前，必须先获得GIL锁，然后，每执行100字节码，解释器就会自动释放GIL锁，让别的线程有机会执行。也就是说多线程在Python上只能交替执行，即使100个线程跑在100个CPU上，也只能用到1个核。
GIL是python解释器设计的历史遗留问题，要想通过多线程利用多核，除非重写不带GIL的解释器。

可以通过多进程实现多核任务，多个Python进程各自独立的GIL锁，互不影响。

#### ThreadLocal
在多线程环境下，每个线程都有自己的数据，一个线程使用自己的局部变量比使用全局变量好。

```
def process_student(name):
	std = Student(name)

def do_task_1(std):
	do_subtask_1(std)
	do_subtask_2(std)

def do_task_2(std):
	do_subtask_2(std)
	do_subtask_2(std)
	
```
发现在函数调用的时候，传递起来很麻烦。
如果用一个全局dict存放所有的Student对象，然后以thread自身作为key获得线程对应的Student对象如何？  
理论上可行，python提供了ThreadLocal来解决子类问题

```
local_school = threading.local()

def process_student():
	std = local_school.student
	print('Hello %s (in %s)' % (std, threading.current_thread().name))

def process_thread(name):
	local_school.student = name
	process_student()

t1 = threading.Thread(target = process_thread,args=('Alice',),name = 'Thread-A')
t2 = threading.Thread(target = process_thread,args=('Bob',),name = 'Thread-B')
t1.start()
t2.start()
t1.join()
t2.join()

```

Threadlocal最常用的地方就是为每个线程绑定一个数据库连接，HTTP请求，用户身份信息等，这样一个线程的所有调用到处理函数都可以方便的访问这些资源。

#### 多进程和多线程的选择

##### 计算密集型 vc IO密集型
是否采用多任务的第二个考虑是任务的类型，我们可以吧任务分为计算密集型和IO密集型
计算密集型的任务的特点是进行大量的计算，销毁CPU的资源，视频解码等，这时候用多任务反而使得执行效率变低，计算密集型的任务同时进行的数量要等于CPU的核心数。  

计算密集型任务由于主要消耗CPU资源，因此，代码运行效率至关重要。Python这样的脚本语言运行效率很低，完全不适合计算密集型任务。对于计算密集型任务，最好用C语言编写。

第二类任务是IO密集型，涉及到网络、磁盘IO的任务都是IO密集型的任务，这类任务的特点是CPU消耗很少。任务带部分时间都在等待IO操作的完成（IO的速度远远低于CPU和内存的速度）  
对于IO密集型任务，最合适的语言就是开发效率最高（代码量最少）的语言，脚本语言是首选，C语言最差。
IO是通过特定的芯片来完成的，一般通过中间人DMA(Direct Memory Access)芯片交互。。




##### 注意事项

* 1.不要有压力(大部分都是我在和自己较真)
* 2.
* 2.感谢长久以来的不嫌弃

















