##### 函数
默认参数的函数
可以简化函数的调用，并增加函数的扩展性

```
def power(x, n=2)
	s = 1
	while n > 0
		n = n - 1
		s = s * x
	return s

power(5)
power(5,3)
```

默认参数注意点，默认参数必须指向不变对象

```
def add_end(L=[])
	L.append('END')
	return L

add_end()
['END']

add_end()
['END','END']

add_end()
['END','END','END']

```

原因是Python函数在定义的时候，默认参数L的值就被计算出来了，即[],因为默认参数L也是一个变量，它指向对象[]，每次调用该函数，如果改变了L的内容，则下次调用时，默认参数的内容就变了，不再是函数定义时的[]了。

```
def add_end(L=None)
	if L is Node:
		L = []
	L.append('END')
	return L
```

#### 可变参数
传入的参数是不固定的

```
def calc(numbers):
	sum = 0
	for n in mubers:
		sum = sum + n * n
	return sum
calc([1,2,3])
```

利用可变参数，调用函数的方式可以简化成

```
calc(1,2,3)
calc(1,3,5,7)
```

可变函数的格式
```
def calc(*numbers):
	sum = 0
	for n in numbers:
		sum = sum + n * n
	return sum
```

定义可变参数和定义一个List或tuple参数相比，仅仅在参数前面加了一个*号。在函数内部，参数numbers接收到的是一个tuple,

list或tuple传入一个可变参数

```
nums = [1,2,3]
calc(*nums)
```
Python允许你在list或tuple前面加一个*号，把List货tuple的元素变成可变参数传进去。

##### 关键字参数
可变参数允许你传入0个或任意个参数，这些可变参数在函数调用时自动组装成一个tuple。而关键字参数允许你传入0个或任意个含参数名的参数，这些关键字参数在内部自动组装成dict

```
def person(name, age, **kw)
 	print('name':name,'age':age,'other',kw)
```

##### 命名关键字参数
用于限制关键字参数的名字，例如只接收city和job作为关键字参数

```
def person(name,age,*,city,job):
	print(name,age,city,job)
	
person('Jack',24,city='Beijin',job='Enginner')
```

如果函数中已经有了一个可变参数，后面跟着的命名关键字参数就不需要一个特殊分隔符*了：

```
def person(name,age,*arg,city,job)
	print(name,age,args,city,job)

person('xx','23','sss','xxx')
由于调用时缺少参数名city和job，Python解释器把这4个参数均视为位置参数，但person()函数仅接收两个位置参数。故而会报错。

```

带默认值的命名关键字参数
```
def person(name,age,*arg,city='beijin',job)
 	print(name,age,arg,city,job)
```

对于任意参数组合，通可以通过类似func(*args,**kw)的形式调用它。


#### 递归函数

我看到最容量理解解决汉诺塔的递归函数

```
def move(n,a,b,c)
	if n == 1:
		print(a,'-->',c)
	else:
		move(n-1,a,c,b)
		move(1,a,b,c)
		move(n-1,b,a,c)
```

#### 高级特性
##### 切片（Slice）
L[0:3]表示，从索引0开始取，直到索引3为止，但不包括索引3.
索引开始为0等价于L[:3]
倒数切片
L[-2:] 从倒数第二个开始取
tuple也可以用切片操作

##### 迭代
python 中迭代是通过for ... in 来完成
只要是可以迭代的对象都可以用for ... in

```
d = {'a':1,'b':2,'c':3}
for key in d:
	print(key)

```
dict迭代的是Key,如果要迭代value可以用for value in d.value,如果要迭代key和value，可以用for k, v in d.items()

判断一个对象是否可以迭代，方法是通过collections模块的iterable类型判断

对list实现类似java那样的下标循环，python内置的enumerate函数可以吧list变成索引-元素对
for i,value in enumerate(['a','b','c'])
	print(i,value)
	
##### 装饰器

函数对象有一个__name__属性，可以拿到函数的名字

在代码运行期间动态增加功能的方式，称之为装饰器("Decorator")

本质上，decorator就是一个返回函数的高价函数，所以，我们要定义一个能打印日志的decorator

```
def log(func):
	def wrapper(*args,**kw):
		print('call %():' % func.__name__)
		return func(*args,**kw)
	return wrapper

@log
def now():
	print('2015-3-25')

```
把@log放到now()函数定义处，相当于执行了语句
now = log(now)

由于log()是一个decorator,返回一个函数，原来的now()函数仍然存在，只是现在同名的now变量指向了新的函数，于是调用now()函数将执行新的函数，即在wrapper中返回的wrapper函数()

如果decorator本身需要传入参数，那就需要编写一个返回decorator的高价函数。

```
def log(text)
	def decorator(func):
		def wrapper(*args,**kw)
			print('%s %s():' % (text,func.__name__))
			return func(*arg,**kw)
		return wrapper
	return decorator

@log('execute')
def now():
	print('2015-3-25')
	
```
三层嵌套的效果是
now = log('execute')(now)

可以看出返回值最终是wrapper函数。所以__name__已经从原来的'now'变成了'wrapper',可以通过functools.wraps模块解决这个问题

```
import functools

def log(func):
	@functools.wraps(func)
	def wrapper(*args, **kw):
		print('call %():' % func.__name__)
		return func(*arg,**kw)
	return wrapper
	
	import functools

def log(text):
    def decorator(func):
        @functools.wraps(func)
        def wrapper(*args, **kw):
            print('%s %s():' % (text, func.__name__))
            return func(*args, **kw)
        return wrapper
    return decorator
```

python直接从语法层次支持decorator,OOP的装饰模式需要通过继承和组合来实现


#### 偏函数
通过设定默认值，可以降低函数调用的难度。而偏函数可以做到这点，通过设置默认值指定成一个新的函数

```
import functools
int2 = functools.partial(int, base = 2)
int2('100000')

max2 = functools.partial(max, 10)
max2(5,6,7)
相当于
max2(10,5,6,7)
```

自定义偏函数实现

```
def my_partial(func, *args, **kw):
	@functools.wraps(func)
	def wrapper(*arg):
		return func(*args+arg, **kw)
	return wrapper
```

#### 第三方模块
通过Anaconada3管理python,安装brew cask install anaconad

设置环境变量
export PATH=/usr/local/anaconda3/bin:"$PATH"

Anaconda3也会给你默认安装一个python3.6的稳定版本，设置python3.7需要进行如下操作

```
conda create -n py37 python=3.7
source activate py37
python -V
```

**注意前面conda自带的一些第三方依赖没有为新安装的3.7设置依赖，只需要安装一下即可**
```
conda install numpy
```

#### 面向对象编程
访问限制
如果要让内部属性不被外部访问，可以把属性名称前加上两个下划线__，表示为私有

class Student(object):

	def __init__(self,name,score):
		self.__name = name
		self.__score = scor
		
创建一个class的实例后，我们可以给实例绑定任何属性和方法，这是动态语言的灵活性
通过__slots__变量，可以限制改class实例能添加的属性

```
clsss Student(object):
	__slots__ = ('name','age')
```

\__slots__关键字只对当前类实例起作用，对继承的子类是不起作用的

#### 定制类

```
__str__



class Student(object):
	def __str__(self):
		return 'xxxxxx'

__iter__
__next__	
class Fib(object):
	"""docstring for Fib"""
	def __init__(self):
		self.a, self.b = 0,1

	def __iter__(self):
		return self

	def __next__(self):
		self.a,self.b = self.b,self.a + self.b
		if self.a > 100000:
			raise StopIteration()
		return self.a
		
__getitem__
可以实现下标访问
		
		
```

当调用不存在的属性的时候，会调用下面方法
```
def _getattr__(self, attr):
```

设置属性时候调用
```
def __setattr__(self, attr):
	
```

下面代码通过重载__getattr__和__setattr__，可以吧self[key]和self.key两种方式关联起来

```
class Model(dict):
	def __getattr__(self,key):
		try return self[key]
	except KeyError:
		raise AttributeError('xxxxx')
		
	def _setattr_(self, key, value):
		self[key] = value
```


#### 枚举类
用法示例
```
from enum import Enum, unique

@unique
class Weekday(Enum):
	Sun = 0
	Mon = 1
	Tue = 2
	Wed = 3
	Thu = 4
	Fri = 5
	Sat = 6
```
@unique装饰器可以帮助我们检查没有重复值。

#### 使用元类
##### type()
动态语言和静态语言最大的不同，就是函数和类的定义，不是编译时定义的，而是运行时动态创建的。
type()函数可以查看一个类型或变量的类型
class的定义是运行时期动态创建的，创建class的方法就是使用type()函数
type()函数既可以返回一个对象的类型，又可以创建出新的类型

type函数创建类
type('类名',(父类,),dict)

要创建一个class对象，type()函数依次传入3个参数:

1. class的名称
2. 继承的父类集合
3. class的方法名称与函数绑定，这里我们把函数fn绑定到方法名hello上

metaclass
除了使用type()动态创建类外，要控制类的创建行为，还可以使用mataclass.
它的解释是：
当我们定义了类以后，就可以根据这个类创建出实例，所以：先定义类，然后创建实例。  
但是如果我们想创建出类呢？那就必须根据metaclass创建出来，所以：先定义metaclass,然后创建类。  
链接起来就是：先定义metaclass,就可以创建类，最后创建实例

```
class ListMetaclass(type):
	def __new__(cls,name,base,attrs):
		attrs['add'] = lambda self, value:self.append(value)
		return type.__new__(cls,name,bases,attrs)
class MyList(list,metaclass=ListMetaclass):
	pass
```
\__new()\__方法接收的参数依次是:

* 1.当前准备创建的类对象；
* 2.类的名字；
* 3.类继承的父类集合；
* 4.类的方法集合

动态修改有什么意义，在MyList定义中写上add()方法不是很简单吗？正常情况下，确实应该直接写，通过metaclass修改纯属变态。  
但是，总会遇到需要metaclass修改类定义的，ORM是一个典型的例子
ORM-Object Relational Mapping,即对象-关系映射，就是把关系数据库的一行映射为一个对象，也就是一个类对应一个表。  
编写一个ORM框架，所有的类都只能动态定义，因为只有使用者才能根据表的结果定义出对应的类来。










#### 文件读写
读写文件是最常见的IO操作。Python内置类读写文件的函数，用法和C是兼容的
在磁盘上读写文件的功能都是由操作系统提供的，现在操作系统不允许普通的程序直接操作磁盘，读写文件就是请求操作系统打开一个文件对象(通常称为文件描述)，然后，通过操作系统提供的接口从这个文件描述中读取数据，或写数据

##### 读文件

```
f = open('Users/jsonsnow/text.txt','r')
```

如果文件读取成功，接下来，调用read()方法可以一次读取文件的全部内容，Python把内容读取到内存，用一个str对象表示  
最后一步是调用close()方法关闭文件。文件使用完毕后必须关闭，因为文件对象会占用操作系统的资源，并且操作系统同一时间打开的文件数量是有限的。

```
f.close()
```

由于文件读写都有可能产生IOError,一旦出错，后面的f.close()就不会调用

```
try:
	f = open('path/to/file','r')
	print(f.read())
finally:
	if f:
		f.close()
		
```

python引入了with语句来自动帮我们调用close()方法：

```
with open('/path/to/file','r') as f:
	print(f.read())
```
read()会一次性读取文件的全部内容，如果文件有10g，内存就爆了，可以反复调用read(size)方法  
readline()可以每次读取一行内容，调用readlines()一次读取所有内容，并按行返回list。因此更具需求决定怎样调用  
如果文件很小，read()一次性读取最方便；如果不确定文件大小，反复调用read(size)比较保险，如果是配置文件readlines()最方便。

```
for line in f.readlines():
	print(line.strip())
```

#### file-like Object
像open()返回的这种有read()方法的对象，在python中统称为file-like Object.除了file外，还可以是内存的字节流，网络流，自定义流等。file-like Object不要求指定类继承，只需要写个read()方法就行。

StringIO就是在内存中创建的file-like Object,常用作临时缓冲。

#### 二进制文件
前面默认都是读取文本文件，并且是UTF-8编码的文本文件，要读取二进制文件，比如图片、视频等等，用'rb'方式打开。

```
f = open('/Users/michal/test.jpg','rb')
f.read()
```	

#### 字符编码
要读取非UTF-8编码的文本文件，需要给open()函数传入encoding参数，例如，读取GBK编码的文件。

```
f = open('Users/snow/michal/gbk.txt','r',encoing='gbk')
f.read()
```

遇到游戏编码不规范的文件，你可能会遇到UnicodeDecodeError,因为在文本文件中可能夹杂了一些非法编码的字符，遇到这种情况，open()还能接收一个errors参数，表示如果遇到编码错误后如何处理。最简单的方式是直接忽略。

```
f = open('/Users/snow/gbk.txt','r',encoding = 'gbk',error='ignore')
```

#### 写文件
写文件和读文件是一样的，唯一区别是调用open()函数时，传入标识符'w'或者'wb'表示文本文件或写二进制文件:

```
f = open('/Users/snow/test.txt','w')
f.write('Hello ,world!')
f.cloe()
```

你可以反复调用write()来写入文件，但是务必调用f.close()来关闭文件。当我们写文件时，操作系统往往不会立刻写入磁盘，而是放在内存缓存起来，空闲的时候再慢慢写入。只有调用close()方法，操作系统才保证把没写入内存的数据全部写入磁盘。

```
with open('/Users/snow/txt.txt','w') as f:
	f.write('Hello ,world!')
```
上面方式会直接覆盖已存在的文件

要写入特定编码的文本文件，请给open()函数传入encoding参数，将字符串自动转换成指定编码。

```
with open('/Users/snow/txt.txt','a') as f:
	f.write('Hello ,world!')
```

#### StringIO和BytesIO
StringIO在内存中读写str

```
from io import StringIO
f = StringIO()
f.write('hello')
f.write(' ')
f.wirte('world!')
print(f.getvalue())
```

BytesIO实现了在内存中读取bytes，

```
from io import BytesIO
f = BytesIO()
f.write('中文'.encode('utf-8'))
print(f.getvalue())

f = BytesIO(b'\xe4\xb8\xad\xe6\x96\x87')
f.read()

```

#### 序列化
在程序运行的过程中，所有变量都是在内存中 
把变量从内存中变成可存储或传输的过程称之为序列化，在python中叫picklink,在其他语言中称之为serialization,marshalling,flatening等等。  
徐序列化之后，就可以吧序列化后的内容写入磁盘，或者通过网络传输到别的机器上。  
反过来，把变量内容从序列化的对象重新独到内存里称之为反序列化，unpicking.
不过pickle是python才能识别，下面介绍json

##### json
```
import json
d = dict(name='bob',age=20,score=88)
json_str = json.dumps(d)
json.loads(json_str)

json_str = ''
```

##### JSON进价

```
import json
class Student(object):
	def __init__(self, name, age, score):
		self.name = name
		self.age = age
		self.score = score
		
def student2dict(std):
	return {
		'name':std.name,
		'age':std.age,
		'score':std.score
	}

		
```
对于自定义对象，需要提供一个序列化的函数

```
json.dumps(s,default=student2dict)
```

#### 进程和多线程

Unix/Linux系统的fork()系统调用，它非常特殊。普通的函数调用，调用一次返回一次，fork()调用一次返回两次，因为操作系统自动把当前进程复制了一份，然后分别在父进程和子进程内返回。

子进程永远返回0，而父进程返回子进程的ID。

```
import os
print('Process (%s) start...' % os.getpid())
pid = os.fork()
if pid == 0:
	print('I am child process （%s）and my parant is %s' % (os.getpid(),os.getppid()))
else:
	print('I (%s) just created a child process (%s).' % (os.getpid(),pid))
```


##### multiprocessing 兼容所有平台的服务程序

multiprocessing 提供了一个Process类来代表一个进程对象。

```
rom multiprocessing import Process, Pool

def run_proc(name):
	print('Run child process %s .' % os.getpid())

if __name__ == '__main__':
	print('Parent process %s.' %  os.getpid())
	p = Process(target=run_proc, args=('test',))
	print('Child process will start')
	p.start()
	p.join()
	print('Child process end.')

```

start()方法启动，join()方法可以等待子进程结束后再继续往下运行，通常用于进程间的同步。
p.terminate() 结束进程

#### Pool

```
from multiprocessing impor Pool

def long_time_task(name):
	print('Run task %s (%s)...' % (name, os.getpid()))
	start = time.time()
	time.sleep(random.random() * 3)
	end = time.time()
	print('Task %s runs %0.2f seconds.' % (name, (end - start)))

if __name__ == '__main__':
	print('Parent process %s.' % os.getpid())
	p = Pool(4)
	for i in range(5):
		p.apply_async(long_time_task,args=(i,))

	print('Waiting for all subprocesses done...')
	p.close()
	p.join()
	print('All subprocesses done')
```

#### 子进程
很多时候，子进程并不是自身，而是一个外部进程。

#### 进程间的通信
Process之间肯定是需要通信的，操作系统提供了很多机制来实现进程的通信。Python的multiprocessing模块包装了底层的机制，提供了Queue,Pipes等多种方式来交互数据。

```
from multiprocessing import Process, Queue

def write(q):
    print('Process to write: %s' % os.getpid())
    for value in ['A', 'B', 'C']:
        print('Put %s to queue...' % value)
        q.put(value)
        time.sleep(random.random())
        

def read(q):
	print('Process to read：%s' % os.getpid())
	while  True:
		value = q.get(True)
		print('Get %s from queue.' % value)

if __name__ == '__main__':
	q = Queue()
	pw = Process(target = write, args=(q,))
	pr = Process(target = read, args=(q,))
	
	pw.start()
	pr.start()

	pw.join()
	pr.terminate()
```


#### 多线程
Python标准库提供了两个模块，_thread和threading,threading是对_threading的封装。

```

import time, threading

def loop():
	print('thread %s is running ...' % threading.current_thread().name)
	n = 0
	while n < 5:
		n = n + 1
		print('thread %s >>> %s' % (threading.current_thread().name,n))
		time.sleep(1)
	print('thread %s ended.' % threading.current_thread().name)

print('thread %s is running ...' % threading.current_thread().name)
t = threading.Thread(target=loop, name='LoopThread')
t.start()
t.join()
print('thread %s ended.' % threading.current_thread().name)

```

#### Lock
多线程和多进程最大的不同在于，多进程，同一个变量，各自有一份拷贝存在每个进程中，互不影响，而多线程中，所有变量由所有线程共享。

```
balance = 0
lock = threading.Lock()
def change_it(n):
	global balance
	balance = balance + n
	balance = balance - n

def run_thread(n):
	for i in range(100000):
		lock.acquire()
		try:
			change_it(n)
		finally:
			lock.release()
		# change_it(n)

t1 = threading.Thread(target=run_thread, args=(5,))
t2 = threading.Thread(target=run_thread, args=(8,))

t1.start()
t2.start()
t1.join()
t2.join()
print(balance)
```

#### 多核CPU
一个死循环会导致执行该线程的CPU跑满

```
def loop():
	x = 0
	while True:
		x = x ^ 1

for i in range(multiprocessing.cpu_count()):
	t = threading.Thread(target=loop)
	t.start()
```
逻辑上来讲有多少核就会跑到x00%，但查看可值python的程序只跑了102，也就是一核。
因为Python的线程虽然是真正的线程，但解释器执行代码时，有一个GIL锁：Global interpreter Lock,任何Python线程执行前，必须先获得GIL锁，然后，每执行100字节码，解释器就会自动释放GIL锁，让别的线程有机会执行。也就是说多线程在Python上只能交替执行，即使100个线程跑在100个CPU上，也只能用到1个核。
GIL是python解释器设计的历史遗留问题，要想通过多线程利用多核，除非重写不带GIL的解释器。

可以通过多进程实现多核任务，多个Python进程各自独立的GIL锁，互不影响。

#### ThreadLocal
在多线程环境下，每个线程都有自己的数据，一个线程使用自己的局部变量比使用全局变量好。

```
def process_student(name):
	std = Student(name)

def do_task_1(std):
	do_subtask_1(std)
	do_subtask_2(std)

def do_task_2(std):
	do_subtask_2(std)
	do_subtask_2(std)
	
```
发现在函数调用的时候，传递起来很麻烦。
如果用一个全局dict存放所有的Student对象，然后以thread自身作为key获得线程对应的Student对象如何？  
理论上可行，python提供了ThreadLocal来解决子类问题

```
local_school = threading.local()

def process_student():
	std = local_school.student
	print('Hello %s (in %s)' % (std, threading.current_thread().name))

def process_thread(name):
	local_school.student = name
	process_student()

t1 = threading.Thread(target = process_thread,args=('Alice',),name = 'Thread-A')
t2 = threading.Thread(target = process_thread,args=('Bob',),name = 'Thread-B')
t1.start()
t2.start()
t1.join()
t2.join()

```

Threadlocal最常用的地方就是为每个线程绑定一个数据库连接，HTTP请求，用户身份信息等，这样一个线程的所有调用到处理函数都可以方便的访问这些资源。

#### 多进程和多线程的选择

实现多任务，通常我们会设计Master-worker模式，Master负责分配任务，worker负责执行任务，多任务环境下，通常是一个Master,多个Worker。

多进程实现Master-worker,主进程就是Master,其他进程就是Worker.
多线程实现Master-Worker,主线程是Master,其他线程就是Worker.

多进程模式的最大的优点是稳定性高，因为一个子进程崩溃了，不会影响主进程和其他子进程（当然主进程挂了所有进程就全挂了，但是Master进程只负责分配任务，挂掉的概率低）著名的Apache最早就是采用多进程模式。  

多进程模式的缺点是创建进程的代价大，在Unix/Linux系统下，用fork调用还行，windows下创建进程开销巨大。另外，操作系统能同时运行的进程数也是有限的，在内存和CPU的限制下，如果有几千个进程同时运行，操作系统连调度都会成问题。  

多线程模式通常比多进程快一点，多线程模式致命缺点就是任何一个线程挂掉都可能直接造成整个进程崩溃

操作系统在切换进程或者线程时也是一样的，它需要先保存当前执行的现场环境（CPU寄存器状态、内存页等），然后，把新任务的执行环境准备好（恢复上次的寄存器状态，切换内存页等），才能开始执行。这个切换过程虽然很快，但是也需要耗费时间。如果有几千个任务同时进行，操作系统可能就主要忙着切换任务，根本没有多少时间去执行任务了，这种情况最常见的就是硬盘狂响，点窗口无反应，系统处于假死状态。

##### 计算密集型 vc IO密集型
是否采用多任务的第二个考虑是任务的类型，我们可以吧任务分为计算密集型和IO密集型
计算密集型的任务的特点是进行大量的计算，销毁CPU的资源，视频解码等，这时候用多任务反而使得执行效率变低，计算密集型的任务同时进行的数量要等于CPU的核心数。  

计算密集型任务由于主要消耗CPU资源，因此，代码运行效率至关重要。Python这样的脚本语言运行效率很低，完全不适合计算密集型任务。对于计算密集型任务，最好用C语言编写。

第二类任务是IO密集型，涉及到网络、磁盘IO的任务都是IO密集型的任务，这类任务的特点是CPU消耗很少。任务带部分时间都在等待IO操作的完成（IO的速度远远低于CPU和内存的速度）  
对于IO密集型任务，最合适的语言就是开发效率最高（代码量最少）的语言，脚本语言是首选，C语言最差。
IO是通过特定的芯片来完成的，一般通过中间人DMA(Direct Memory Access)芯片交互。。

#### 异步IO
考虑到CPU和IO之间巨大的速度差异，一个任务在执行的过程中大部分时间都在等待IO操作，单进程单线程模式会导致别的任务无法执行，因此，我们需要多进程模型或多线程模型来支持多任务并发执行。  

现代操作系统对IO操作已经做了巨大的改进，最大的特点是支持异步IO，如果充分利用操作系统提供的异步IO支持，就可以用单进程单线程模型来执行多任务，这种全新的模型称为事件驱动模型，Nginx就是支持异步IO的web服务器，它在单核CPU上采用单进程模型就可以高效地支持多任务，在多核CPU上，可以运行多个进程，充分利用多核CPU。由于系统总的进程数量十分有限,因此操作系统的调度非常高效，用异步IO编程模型来实现多任务是一个主要的趋势。  

对于python语言，单线程的异步编程模型称为协程，有了协程的支持，就可以基于事件驱动编写高效的多任务程序。


#### 分布式进程
在Thread和Process中，应当优选Process，因为Process更加稳定，而且Process可以分布到多台机器上，而Thread最多只能分布到同一台机器的多个CPU上。  

Python的multiprocessing模块不但支持多进程，其中managers子模块还支持多进程分布到多台机器上。

Queue对象存储在哪，注意到task_worker.py中没有创建Queue的代码，所以,Queue对象存储在task_master.py进程中。

Queue的作用是用来传递任务和接收结果，每个任务的描述数据要尽量小，比如发送一个处理日志的文件任务，就不要发送几百兆的日志文件本身，而是发送日志文件存放的完整路径。


#### 正则表达式

##### 匹配字符串

```
import re
re.match(r'^\d{3}\-\d{3,8}&','010-123456')
```

##### 切分字符串

```
re.split(r'\s+','a b  c')
['a','b',','c']
```

##### 分组

m = re.match(r'^(\d{3})-(\d{3,8})$','010-12345')
print(m.group(0))
print(m.group(1))
print(m.group(2))

```

##### 编译
当我使用Python中使用正则表达式时，re模块内部会干两件事情：

* 1.编译正则表达式，如果正则表达式的字符串本身不合法，会报错；
* 2.用编译后的正则表达式去匹配字符串。

如果一个正则表达式要重复使用几千次，出于效率的考虑，我们可以预编译改正则表达式，接下来重复使用时就不需要编译这个步骤了。

```
re_telephone = re.compile(r'^(\d{3})-(\d{3,8})$')
print(re_telephone.match('010-123456').groups())
print(re_telephone.match('010-8086').groups())

```

#### base64
base64是一种用64个字符来表示任意二进制数据的方法，一个常用的二进制编码方法。  

Base64的原理很简单，首先，准备一个包含64个字符的数组。

二进制数据每三个字节一组，一共是3*8bit,划为4组，每组6个bit
可以看出Base64编码会吧3字节的二进制数据编码为4字节码的文本数据，长度增加了33%,好处是编码后的文本数据可以在邮件正文、网页等直接显示。  

如果要编码的二进制数据不是3的倍数，最后剩1个或2个字节怎么办，Base64用\x00字节在末尾补足后，仔仔编码末尾加上1个或2个=号，表示补了多少个字节，解码的时候，会自动去掉。

```

enStr = base64.b64encode(b'binary\x00string')
print(enStr)
deStr = base64.b64decode(enStr)
print(deStr)

输出信息
b'YmluYXJ5AHN0cmluZw=='
b'binary\x00string'
```

标志的Base64编码可能出现+和/,在URL中不能直接作为参数，url safe base64,可以吧字符+和/变成-和——

```
>>> base64.b64encode(b'i\xb7\x1d\xfb\xef\xff')
b'abcd++//'
>>> base64.urlsafe_b64encode(b'i\xb7\x1d\xfb\xef\xff')
b'abcd--__'
>>> base64.urlsafe_b64decode('abcd--__')
b'i\xb7\x1d\xfb\xef\xff'
```

Base64是一种通过查表的编码方法，不能用于加密，即使用自定义的编码表也不行。

由于=字符也可能出现在Base64编码中，但=用在URL、Cookie里面会造成歧义，所以，很多Base64编码后会把=去掉：

去掉=后怎么解码呢？因为Base64是把3个字节变为4个字节，所以，Base64编码的长度永远是4的倍数，因此，需要加上=把Base64字符串的长度变为4的倍数，就可以正常解码了。


```
import base64
def safe_base64_decode(s):
	if len(s) % 4 != 0:
		num = 4 - len(s) % 4
		s = s + b'=' * num
	return base64.b64decode(s)

assert b'abcd' == safe_base64_decode(b'YWJjZA=='), safe_base64_decode('YWJjZA==')
assert b'abcd' == safe_base64_decode(b'YWJjZA'), safe_base64_decode('YWJjZA')
```


#### itertools 
itertools提供了非常有用的用于操作迭代对象的函数,它创建的是一个迭代对象

```
natuals = itertools.count(start = 1,step = 2)
for n in natuals:
	print(n)
n = itertools.repeat('A',3)
ns = itertools.takewhile(lambda x:x <=10, natuals)
list(ns)

for c in itertools.chain('abc','xyz')
	print(c)
	
for key ,group in itertools.groupby('AAABBBCCAAA'):
	print(key, list(group))
	
```


#### contextlib

任何对象，只要正确实现了上下文管理，就可以用with语句。
实现上下文管理是通过__enter__和__exit__这两个方法实现的

```
class Query(object):

    def __init__(self, name):
        self.name = name

    def __enter__(self):
        print('Begin')
        return self

    def __exit__(self, exc_type, exc_value, traceback):
        if exc_type:
            print('Error')
        else:
            print('End')

    def query(self):
        print('Query info about %s...' % self.name)
```

##### @contextmanager
contextlib提供了更简单的写法

```
rom contextlib import contextmanager
class Query(object):
	def __init__(self, name):
		self.name = name
	def query(self):
		print('Query info about %s ...' % self.name)


@contextmanager
def create_query(name):
	print('Begin')
	q = Query(name)
	yield q
	print('End')
	
```

@contextmanager这个decorator接收一个generator,用yield语句把with ... as var 把变量输出出去，然后，with语句就可以正常工作了。

```
with create_query('Bob') as q:
	q.query()
```

很多时候，我们希望在某段代码执行前后自动执行特定代码，也可以用@contextmanager实现

```
@contextmanager
def tag(name):
	print('<%s>' % name)
	yield
	print('</%s>' % name)

with tag('h1'):
	print('hello')
	print('world')
```
这里的两个输出语句可以是其他函数

__@contextmanager让我们通过编写generator来简化上下文管理__

##### @closing
如果一个对象没有实现上下文，我们就不能把它用于with语句，这个时候，可以用closing()来把该对象变为上下文对象。例如

```
rom contextlib import closing
from urllib.request import urlopen

with closing(urlopen('https://www.python.org')) as page:
	for line in page:
		print(line)
```

closing是一个经过@contextmanager装饰的generator

```
@contextmanager
def closing(thing):
	try:
		yield thing
	finally:
		thing.close()
```


#### Pillow


#### virtualenv
在开发Python应用程序的时候，系统安装的Python3只有一个版本：3.4.所有第三方的包都会被pip安装的python3的site-packages目录下。

virtualenv可以为应用创建一套“隔离”的Python运行环境。

```
virtualenv --no-site-packages venv
```
--no-site-packages,这样，已经安装到系统Python环境中的所有第三方包都不会复制过来，我们就得到了一个不带任何第三方包的“干净”的Python运行环境。
新建的Python环境被放到当前目录下venv目录，可以用source进入该环境：

```
source venv/bin/activate
(venv) (py37) chendeiMac:myproject chenliang$ 
```

退出
```
deactivate
```
virtualenv为应用提供了隔离的Python运行环境，解决了不同应用间多版本的冲突问题。


#### TPC/IP简介

互联网协议包含了上百种协议标准，但是最重要的两个协议是TCP和IP协议，所有，大家把互联网的协议简称TCP.IP协议。  

__IP协议负责把数据从一台计算机通过网络发送到另一台计算机__。数据被分割成一小块一小块，然后通过IP包发送出去。由于互联网链路复杂，两台计算机之间经常有多条线路，因此路由器就负责决定如何把一个IP包转发出去。IP包的特定是按块发送，途径多个路由，但不能保证能达到，也不能保证顺序到达。  

TCP协议则是建立IP协议之上的。TCP协议负责在两台计算机之间建立可靠连接，保证数据包按照顺序到达。  

TCP协议会通过握手建立连接，然后，对每个IP包编号，确保对方按照顺序接收到，如果丢包，就自动重发。  

许多常用的更高级协议都是建立在TCP协议基础上的，如浏览器的HTTP，发送邮件的SMTP。


####  数据库


#### zip函数简介

```
zip([iterable, ...])
```
参数iterable为可迭代的对象，并且可以有多个参数， 该函数返回一个以元组为元素的列表，其中第i个元组包含每个参数序列的第i个元素。返回的列表长度被截断为最短的参数序列长度，只有一个序列参数时，它返回一个一元元组的列表。

```
a = [1, 2, 3]
b = [2,3,4]
d = 'abcde'
zz = zip(a, b, d)
print(zz)
[(1,2,a),(2,3,b),(3,4,c)]
```
只有一个参数的时候
```
a = [1,2,3]
print(zip(a))
[(1,), (2,), (3,)]
```
zip和*操作费一起操作可以用来unzip一个列表

```
a = [1, 2, 3]
b = [2,3,4]
d = 'abcde'
zz = zip(a, b, d)
print(zz)
[(1,2,a),(2,3,b),(3,4,c)]

x, y, z = zip(*zz)
(1, 2, 3)
(4, 5, 6)
(a, b, c)
```


















